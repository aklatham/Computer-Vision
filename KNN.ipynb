{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdL218vekrI3"
      },
      "source": [
        "## K nearest neighbor ([KNN](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)) on [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q1GYRkylFaY"
      },
      "source": [
        "###In this exercise, we will apply KNN to classify the CIFAR-10 dataset. CIFAR-10 consists of 32x32 images from 10 classes. The train set consists of 50k images and the test set consists of 10k images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXPHVuTGkvQG"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpVYHz4DkxO-"
      },
      "source": [
        "###Function to load CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgg8Mwe1lc1v"
      },
      "source": [
        "def fetch_dataloader(transform=None, batch_size=-1, is_train=True):\n",
        "    \"\"\"\n",
        "    Loads data from disk and returns a data_loader.\n",
        "    A DataLoader is similar to a list of (image, label) tuples.\n",
        "    You do not need to fully understand this code to do this assignment, we're happy to explain though.\n",
        "    \"\"\"\n",
        "    data = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                            train=is_train, download=True, transform=transform)\n",
        "    batch = len(data) if batch_size is -1 else batch_size\n",
        "    loader = torch.utils.data.DataLoader(data, batch_size=batch,\n",
        "                                              shuffle=True, num_workers=4)\n",
        "      \n",
        "    return loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVxYWxdQld9b"
      },
      "source": [
        "##Fetch and preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AndJ2I-Elg8V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0c0e6750-4b0b-438e-88e1-f19ade2d7273"
      },
      "source": [
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "transform = transforms.Compose(\n",
        "            [transforms.ToTensor(),\n",
        "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = -1\n",
        "\n",
        "loader_trn = fetch_dataloader(transform, batch_size, is_train=True)\n",
        "\n",
        "x_trn, y_trn = iter(loader_trn).next()\n",
        "print(x_trn.shape, y_trn.shape)\n",
        "\n",
        "testset = fetch_dataloader(transform, batch_size, is_train=False)\n",
        "x_test, y_test = iter(testset).next()\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "print(x_trn.dtype, x_test.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "torch.Size([50000, 3, 32, 32]) torch.Size([50000])\n",
            "Files already downloaded and verified\n",
            "torch.Size([10000, 3, 32, 32]) torch.Size([10000])\n",
            "torch.float32 torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osO5p9vB-dxF"
      },
      "source": [
        "You might also want to modify the code above and get the testing data.  You can use testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform) or you can use fetch_dataloader()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA6eU9TY-HNH"
      },
      "source": [
        "# Part1 Visualize the exampes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1020P2Jx-KRZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "b50ff913-9fdb-45e8-8284-216c88e2d178"
      },
      "source": [
        "# Visualize some examples from the dataset.\n",
        "# We show a few examples of training images from each class.\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "num_classes = len(classes)\n",
        "samples_per_class = 7\n",
        "#TODO\n",
        "\n",
        "def disp_img(num):\n",
        "      img = x_trn[num,:,:,:] / 2 + 0.5    \n",
        "      img = img.numpy()\n",
        "      img = np.transpose(img, (1, 2, 0))\n",
        "      plt.imshow(img)\n",
        "      print(classes[y_trn[num]])\n",
        "\n",
        "disp_img(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-330de688945c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_trn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdisp_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-330de688945c>\u001b[0m in \u001b[0;36mdisp_img\u001b[0;34m(num)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisp_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_trn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_trn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VgYixrn-Tch"
      },
      "source": [
        "Part 2: KNN implementation. \n",
        "We would now like to classify the test data with the kNN classifier. Recall that we can break down this process into two steps:\n",
        "\n",
        "First we must compute the distances between all test examples and all train examples.\n",
        "Given these distances, for each test example we find the k nearest examples and have them vote for the label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8IwDFrlcuD7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a159694-6102-4cdf-92d9-ad264a926e09"
      },
      "source": [
        "#format datasets for eaier handling\n",
        "\n",
        "shave = 5000\n",
        "shave = list(range(shave))\n",
        "x_trn = x_trn[shave]\n",
        "y_trn = y_trn[shave]\n",
        "\n",
        "shave = 500\n",
        "shave = list(range(shave))\n",
        "x_test = x_test[shave]\n",
        "y_test = y_test[shave]\n",
        "\n",
        "x_test_save = x_test\n",
        "\n",
        "x_trn = np.reshape(x_trn, (x_trn.shape[0], -1))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], -1))\n",
        "print(x_trn.shape, x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5000, 3072]) torch.Size([500, 3072])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba0TJMXNlqkZ"
      },
      "source": [
        "class KNearestNeighborClassifier(object):\n",
        "\n",
        "    def __init__(self, k):\n",
        "      self.k = k\n",
        "\n",
        "    def train(self, x_trn, y_trn):\n",
        "      self.x_trn = x_trn\n",
        "      self.y_trn = y_trn\n",
        "      pass\n",
        "      \n",
        "    def predict(self, images):\n",
        "\n",
        "      tests = images.shape[0]\n",
        "      trains = self.x_trn.shape[0]\n",
        "      l1dists = np.zeros((tests, trains))\n",
        "      l2dists = np.zeros((tests, trains))\n",
        "\n",
        "      for i in range(tests):\n",
        "        for j in range(trains):  \n",
        "          delta = np.abs(images[i] - x_trn[j])\n",
        "          l1dists[i][j] = np.sum(delta.numpy())\n",
        "          l2dists[i][j] = np.sqrt(np.sum(np.square(delta.numpy())))\n",
        "       \n",
        " \n",
        "      predictions = np.zeros(tests)\n",
        "      for i in range(l2dists.shape[0]):\n",
        "        close = []\n",
        "        close = np.take(self.y_trn, np.argsort(l2dists[i]))[:self.k]\n",
        "      \n",
        "        (values, counts) = np.unique(close, return_counts=True)\n",
        "        predictions[i] = values[np.argmax(counts)]\n",
        "     \n",
        "\n",
        "      return predictions, l1dists, l2dists\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzpcQAQImHe-"
      },
      "source": [
        "Here you can call your function and output results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ1QkK6LMq_Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d244e0aa-4790-4f8d-ac3f-54f4177465b1"
      },
      "source": [
        "#test with k = 10\n",
        "\n",
        "c = KNearestNeighborClassifier(10)\n",
        "c.train(x_trn, y_trn)\n",
        "output = c.predict(x_test)\n",
        "predict = output[0]\n",
        "l1 = output[1]\n",
        "l2 = output[2]\n",
        "\n",
        "correct=0\n",
        "for i in range(predict.size):\n",
        "  if(predict[i] == y_test[i]):\n",
        "    correct += 1\n",
        "accuracy = float(correct) / predict.size\n",
        "print('%d of %d correct with accuracy of: %f' % (correct, predict.size, accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153 of 500 correct with accuracy of: 0.306000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jb4ZT53Lhma",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "06de4472-7057-40a7-f063-7d47d0e84676"
      },
      "source": [
        "#example output\n",
        "\n",
        "def example(num):\n",
        "      img = x_test_save[num,:,:,:] / 2 + 0.5    \n",
        "      img = img.numpy()\n",
        "      img = np.transpose(img, (1, 2, 0))\n",
        "      plt.imshow(img)\n",
        "      print('predicted label: ' + classes[int(predict[num])])\n",
        "      print('actual label: ' + classes[y_test[num]])\n",
        "      print('l1: %f' % np.min(l1[num]))\n",
        "      print('l2: %f' % np.min(l2[num]))\n",
        "\n",
        "example(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted label: ship\n",
            "actual label: ship\n",
            "l1: 929.082397\n",
            "l2: 23.124441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}